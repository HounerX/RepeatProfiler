#!/bin/bash

#we will miss you pileup :(
commands=$@

num_commands=`echo $commands | wc -w ` #gets the number  of commands

if ((num_commands == 0 )) # if no commands entered, show this
 then
echo "RepeatProfiler v 0.91 -prerelease- x Correlation x and x Reinforcements x"
echo "please use -h flag to view help menu for how to use this tool"


echo "____ ____ ___  ____ ____ ___    ___  ____ ____ ____ _ _    ____ ____"
echo "|__/ |___ |__] |___ |__|  |     |__] |__/ |  | |___ | |    |___ |__/ "
echo "|  \ |___ |    |___ |  |  |     |    |  \ |__| |    | |___ |___ |  \ "


exit 1

fi

rm -f -r  *.out *.bam *fofn* Errors_README.log normalized_table.csv #images-RP #brew stuff

currentDate=`date`
currentDate=`tr ' :' '_' <<<"$currentDate"`
rm -f Errors_README.txt
#echo $currentDate




#brew link --overwrite >/dev/null 2>&1  #brew stuff


#mydir=`echo "$(brew --cellar repeatprof)/0.91/libexec"` #brew stuff

R_packages="placeholder"
#R_packages=`echo "$(brew --cellar repeatprof)/0.91/R_packages"` #brew stuff

#images=`echo "$(brew --cellar repeatprof)/0.91/images-RP"`  #brew stuff
#Rscript=`echo "$(brew --prefix R)/bin/Rscript"`  #brew stuff

mydir=`pwd` #comment when running it for brew
Rscript="Rscript" #comment when running it for brew
#dont forget to cp the image when in brew mode




if  [[ $1 == "profile" ]] ||  [[ $1  ==  "clean" ]] || [[ $1 ==  "-h" ]] || [[ $1 == "pre-corr" ]]; then  # check if the 2nd parameter is any of these. If not, terminate the program and tell the user.

echo "" > /dev/null


else

echo "wrong command structure please use -h to view a sample command or refer to the manual"
exit 1


fi





currentdir=`pwd`

if [ "$1" == "profile" ]; then  # check if the second parameter is profile, If yes then preform profiling stuff

#cp -r $images $currentdir #brew stuff
if  [[ $2 == "-u" ]] ||  [[ $2  ==  "-p" ]]; then # check if the user inputed -u or -p if not give him an error as it is a madantory command

echo "" > /dev/null


else

echo "second parameter should be -u or -p"
exit 1


fi

if (( num_commands < 4 )) #If commands are less than 4 (which is number of the 4 madantory flags for profile)
 then

echo "Not all madantory flags were used. please review a sample usage using  the  -h flag to view help menu"

exit 1

fi

commands=$@ #this gets all paremertes of a command. It is a shell thing
array=(${commands})   # this is able to put a string sperated by spaces in an array, so this basically put the parameters in array
index=0 # this keep track of the index while looping through array by element.

for t in "${array[@]}"  #for each element in the array
do

if [[ $t  ==  "-o" ]]; then # this if statement says if the flag in the array is -o  (stands for output folder directory ) then check for the next element in the array
	((index ++))

	the_path=${array[index]}

	    if [[ -d $the_path ]]; then

		 echo "the output will be at  $the_path  as you specified"

		else
		   echo "the output directory specified is not correct. Please make sure it has no blanks and it is valid or dont specify and it will output the folder in current directory"

		   exit 0
		fi






    fi
		((index ++))

done

# all the flag  checks are done in the same way for optional flag  as the example i explained above ^








array=(${commands})
index=0

for p in "${array[@]}"
do
if [[ $p  ==  "-corr" ]]; then
	((index ++))
#this is code to get reads fofn early 

if [ $2 = "-p" ]; then #if user specified paired data  then look for this 

ls ${4}/*_R1.fastq ${4}/*_R1.gz ${4}/*_R1.fq ${4}/*_R1.fq.gz  ${4}/*_1.fq ${4}/*_1.fq.gz ${4}/*_1.gz ${4}/*_1.fastq > fofn1.txt 2>/dev/null

ls ${4}/*_R2.fastq ${4}/*_R2.gz ${4}/*_R2.fq ${4}/*_R2.fq.gz  ${4}/*_2.fq.gz  ${4}/*_2.fq ${4}/*_2.gz ${4}/*_2.fastq > fofn2.txt 2>/dev/null


fi
if [ $2 = "-u" ]; then #if user specified unpaired data  then look for that. We use it double here because rest of the code was built on paired data, but dont worry it gets dealt with later

ls ${4}/*.fastq ${4}/*.gz ${4}/*.fq     > fofn1.txt 2>/dev/null

ls ${4}/*.fastq ${4}/*.gz ${4}/*.fq    > fofn2.txt 2>/dev/null





fi


#we check if the lines of the fofn for pair 1 is equal to lines fofn of pair 2 if not then give an error because that mean user has missing data if paired  

reads1_check=`cat fofn1.txt | wc -l` 
reads2_check=`cat fofn2.txt | wc -l `



if [[ $reads1_check == 0 && $reads2_check == 0 ]];then #if both are empty then there was no reads of correct format to begin with 
echo ""

echo "The path of a file of  paired  read  provided doesnt contain any paired read that has correct format."| tee -a Errors_README.log
echo "Make sure your read pairs  are in .fastq or .gz or .fq AND revise the path inputed. Make sure there is no blanks in path"| tee -a Errors_README.log
echo "Analysis wont be able to continue due to the failure of finding reads"
exit 1


fi

if [ "$reads1_check" != "$reads2_check" ]; then

echo "There is a pair of read missing. Please check the folder where you have your paired reads "| tee -a Errors_README.log
exit 1
fi
#ls ${DIR}/*.fa > fofn3.txt


#counts number of lines in fofn1.txt and stores variable as MAX
MAX=`wc -l < fofn1.txt`


#ends early  reads check 

	user_prov=${array[index]}
	    if [[ -f $user_prov ]]; then
		rm -f user_provided.txt
        lines=`cat $user_prov | wc -l`
		lines=`echo $[$lines-1]`
	    if [[ $lines != $MAX ]]; then
           echo "your user-provided doesnt match your reads in the reads path you provided. Please double check your steps"
		   echo "if you created your user_provided.txt using -u you need to have -u in your profile command same for -p"
		   exit 1 
         fi		
        
		currentdir=`pwd`

		 cp $user_prov  $currentdir
		 
		 

		elif [[ -f user_provided.txt ]]; then
        lines=`cat user_provided.txt | wc -l`
		lines=`echo $[$lines-1]`
	    if [[ $lines != $MAX ]]; then
           echo "your user-provided doesnt match your reads in the reads path you provided. Please double check your steps"
		   echo "if you created your user_provided.txt using -u you need to have -u in your profile command same for -p"
		   exit 1 
         fi		
	     echo '' > /dev/null

		else

		   echo "no user_provided.txt path is provided and it is not present in the current directory. Please refer to repeatprof -h to understand how to create it"

		   echo "it must be provided for correlation analysis to continue"

		   exit 0



		fi





    
    fi
	((index ++))
done






The_folder="$currentDate-RepeatProfiler"
mkdir $The_folder # this creates the main output folder u see at the end


BASE="refbase_" #this is just for the naming of the refrence index made by bowtie2-build, so it can be detected later when aligning using bowtie2
commands=$@


#it works





if [[ -d $3 ]]; then # checking if 3rd parameter (refrence path) for profile is directory or a file
#if it is a directory then sum up all the .fa files and put them into one and send them to fasta splitter  to prepare them as  single fasta sequences for analysis
	rm -f -r Refrences_used
	mkdir Refrences_used
	path_refs=`cat $3/*.fa > all_refs.fa`


bash $mydir/Fasta_splitter.sh $3


retval=$? #check if any error occured by getting the exit code

if [ $retval -eq 2 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from map_mileup not here

exit 1

elif [ $retval -ne 0 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from map_mileup not here

	echo "something is wrong with refrence file inputed. Please make sure it is in correct fasta format and dont contain \ in the names"
exit 1

fi


	refs=Refrences_used #this is where bowtie will look for refrence sequence ot align. It is a sub directory

elif [[ -f $3 ]]; then # if the refrence entered as a file  then just send it to fasta splitter in case it is multi sequence fasta
	rm -f -r Refrences_used
	mkdir Refrences_used



bash $mydir/Fasta_splitter.sh $3

retval=$? #check if any error occured by getting the exit code

if [ $retval -eq 2 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from map_mileup not here

exit 1

elif [ $retval -ne 0 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from map_mileup not here

	echo "something is wrong with refrence file inputed. Please make sure it is in correct fasta format and dont contain \ in the names"
exit 1

fi

refs=Refrences_used


else
    echo "The path to folder of Refrences files  or The path to your Refrecnes file is not valid"
    exit 1
fi


##this is just make sure no duplicates is there
rm -f -r Errors.log  2> /dev/null
rm *bam *bt2  2> /dev/null
rm -f -r all_depth_cvs  2> /dev/null
######

mkdir all_depth_cvs #this creates all_depth_cvs where it store  a table of postion of refrence and the coverage depth (the folder will be used later by $Rscripts)


Normalized=false #this is equal 1 always unless the user chooses to normalize 

rm -f *out  2> /dev/null

#here we will insert single copy stuff 

for i in "${array[@]}"
do

if [[ $i == "-singlecopy" ]]; then
  



a="--very-sensitive-local"
commands=$@
array=(${commands})

for i in "${array[@]}"
do

if [[ $i  ==  "--very-fast" ]] || [[ $i  ==  "--local" ]] || [[ $i  ==  "--fast" ]] || [[ $i  ==  "--sensitive" ]] || [[ $i  == "--very-sensitive" ]] || [[ $i  ==  "--very-fast-local" ]] || [[ $i  ==  "--fast-local" ]] || [[ $i  ==  "--sensitive-local" ]] || [[ $i  ==  "--very-sensitive-local" ]]; then
		a=$i
    fi
done

echo ""


echo "The alignment setting for single copy calculations  is $a"


bash $mydir/singlecopy.sh $mydir $4 $2 "2" $a

retval=$? 

if [ $retval -ne 0 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from singlecopy.sh not here

exit 1

fi

Normalized=true
readnumbers=`cat fofnsingle.txt | wc -l`
echo "The Normalization values calculated:"
$Rscript $mydir/single_copy_Calculator.R $readnumbers

#rm -f The_summary.txt 


echo "Normalization calcaulations ended "


### 

fi
done 

###end of single copy stuff 


ls $refs/*.fa > fofnrefs.txt  2> /dev/null #the folder where fasta spliter stores all the .fa file after splitting them. This line just gets a list of these refrences with their paths

fofncheck=`cat fofnrefs.txt | wc -l` 

if [[ $fofncheck == 0 ]];then #if both are empty then there was no reads of correct format to begin with 

echo "it seems like you had only _singlecopy refrences in your fasta file.The program also additional  actual sequences to analyze"
echo "or rerun without -singlecopy if you want to anlayze any sequence in the fasta file "

exit 1
fi



echo "Reference	Sample_index	Read1	Read2	Total_reads	percent_mapped" > The_summary.txt #preparing the summary table







while read line  # for each line  in the fofnrefs.txt we will loop through it and  carry the following analysis
do

ref_char_count=`tail -n +2 $line | tr -cd 'ATGCatgc'  | wc -c` #this gets the refrence sequence length
name_ref=$(awk -F "/" '{print $NF}' <<< $line) # this awk command is to get the refrence name from the path of refrences stored in fofnrefs.txt we did earlier
											   # this command sepeartes on / and get the last word which is the refrence name


if [[ $ref_char_count == 0 ]]; then			   # if the  the length of the specfic refrence is 0 then just skip it.
											   # it skips it by just printing the below message and nothing else will be executed because everything done is in the else statemen of this
echo ""
echo "your $name_ref is an empty sequence or not in the correct format. It wont be analyzed or indexed. Please revise it " | tee -a Errors_README.log
echo ""


else

echo "$(tail -n +2 $line)" > ref_temp.txt #this does something similar to above

The_ref_size=`wc -c < ref_temp.txt` #same as above re_char_count

bash $mydir/Readmegen.sh #this starts generating the readme. which will be populated later with the index to read conversions

    bowtie2-build $line $BASE > /dev/null 2> /dev/null # this build index for the current refrence
    echo "The name of the reference  sequence whose index was built and currently under analysis :"
    echo "$line"
    echo ""



#bash index_refs.sh
name_ref=$(awk -F "/" '{print $NF}' <<< $line) #same as above just to make sure

Ref_name=$name_ref #assigning it to another variable

stringe="$Ref_name"
stringee="_output"
the_output="$stringe$stringee" #i sum up both variables to create the suboutput folder for that refrence REFname_ouput. The one you see in the big folder
rm -f -r $the_output
mkdir $the_output


echo "$the_output" >>fofn_Theoutputs.txt #this appends the fofn_the outputs with the current name (it gets created by the first append at the first refrence rest is appennding)
										 # keeping track of the folder names will help in the future when assigining stuff to each folder







numPairpile=1 #this will keep count of the index reads


p=8 #this is the deafult threads

commands=$@
array=(${commands})
index=0
#we did this before we will check if -t was entered in optional arguments
for th in "${array[@]}"
do

if [[ $th  ==  "-t" ]]; then
	((index ++))

	p=${array[index]}


	    re='^[0-9]+$'
	if ! [[ $p =~ $re ]] ; then #make sure the user entered a number for threads not some nonsense words
	p=8
	fi






fi
		((index ++))

done
echo "Threads used: $p" #prints to the user what threads is being used




#the following is the same checking for optional flag but this time it is for bowtie alignment settings

a="--very-sensitive-local"
commands=$@
array=(${commands})

for i in "${array[@]}"
do

if [[ $i  ==  "--very-fast" ]] || [[ $i  ==  "--local" ]] || [[ $i  ==  "--fast" ]] || [[ $i  ==  "--sensitive" ]] || [[ $i  == "--very-sensitive" ]] || [[ $i  ==  "--very-fast-local" ]] || [[ $i  ==  "--fast-local" ]] || [[ $i  ==  "--sensitive-local" ]] || [[ $i  ==  "--very-sensitive-local" ]]; then
		a=$i
    fi
done



if [[ $@  ==  *"-D"* ]]; then
commands=$@
a=`echo "$commands" | awk '{for (I=1;I<=NF;I++) if ($I == "-D") {print $I " " $(I+1) " " $(I+2) " " $(I+3)" " $(I+4) " " $(I+5) " " $(I+6) " " $(I+7) " " $(I+8) " " $(I+9) };}' `


fi



echo "Bowtie2 alignment settings: $a"

####

bash $mydir/map_mpileup.sh $line $4 $2 $p $a  #here we call map_mpileup.sh which runs bowtie aligning and uses the indexes we built and also run samtools pileup
retval=$? #check if any error occured by getting the exit code

if [ $retval -ne 0 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from map_mileup not here

exit 1

fi

echo "name_poly" > multi_poly_names.txt #this creates a text file called multi_poly_names.txt this is used to keep track of the reads that we are drwaing the graphs for
										# LIKE for example Refrencename_001  001 refrence to the read the index we talked about before
rm -f -r multi_poly
mkdir multi_poly
rm -f temp_cvs
mkdir temp_cvs #this store the current postion vs coverage depth of the current refrence (this is used in r script)
while read pairpile # for each pair pile this means for each pileup output from the map_mpileup
do

F=`printf "%03d\n" $numPairpile` #this convert 1 to 001 for example this allow naming to be in order

pile_counted_name="${Ref_name}_${F}" #this is the pileup counted name

echo $pile_counted_name >> multi_poly_names.txt #now populate the  multi_poly_names

python $mydir/pileup_basecount_sink.py $pairpile $pile_counted_name $The_ref_size # this pileup script that counts mismatches from the sam pileup.out file and count depth and all aother info


cp "$pile_counted_name.csv" all_depth_cvs # cp the selected .csv produced by the python script
mv "$pile_counted_name.csv" temp_cvs #this moves it to temp_cvs  also. both steps are needed to be done because all_depths_cvs runs at the end for the all refrences statistcs   while temp_cvs just for this refrence combined graphs and scaling

output=$Ref_name

stringpile2="$F"
stringpile3="_"
output="$output$stringpile3$stringpile2" #this just combines the output with its number to create the sub folder of the refrence folder you see REF_001 for example where it contains the graphs

echo "$output" >> fofn_folders.txt #adds the name to the fofn_folders.txt
$Rscript $mydir/polymorphism_2.0.R $output $R_packages  # call polymorphism $Rscripts



rm -f -r $output

mkdir $output
mv  *.png  pileup_counted.txt  $output
#mv $output $the_output  # we are not moving now  we move in next pile up loop

((numPairpile ++))

done < fofn_pileup.txt #after finishing all the maping and creating the csv files now we can start plotting graphs by scaling among all data


while read folder_names #for each line in folder name where we stored the folder name like REF_001
do


echo $folder_names #say it

$Rscript $mydir/RP_4.0.R $folder_names $R_packages $Normalized #run $Rscripts

mv $folder_names $the_output
done < fofn_folders.txt


$Rscript $mydir/All_RP_graphs_reference.R $R_packages $Normalized


$Rscript $mydir/multi_Poly_maker.R $R_packages


#move R scripts
mv *combined* $the_output
rm -f *.phy
$Rscript $mydir/fraction_bases.R  > Closely_related_reads_analysis.txt

mv *.phy $the_output

mv *variation_analysis* $the_output
rm -f Closely_related_reads_analysis.txt #we dont need this anymore







if [[ $@  ==  *"-corr"* ]]; then #if the user enter -corr check for user_provided.txt is in the same directory then run it and see if there is errors and run it

rm -f  R_correlation_errors.txt

if [[ !(-f user_provided.txt) ]]; then

echo "user_provided.txt wasnt provided, so the graph of correlation between reads for a refrence  wont be produced. Only the matrix." > R_correlation_errors.txt

fi


$Rscript $mydir/Corr_test.R $the_output $R_packages $Normalized  2> /dev/null


if [ -f R_correlation_errors.txt ]; then


mv R_correlation_errors.txt $the_output
fi













#mv multi_poly $the_output    uncomment when testing
#mv multi_poly_names.txt $the_output

#thats check for -k which says where to keep bam file or not

commands=$@
array=(${commands})
index=0

for k in "${array[@]}"
do

if [[ $k  ==  "-k" ]]; then


		mv *.bam *.out $the_output




fi
		((index ++))

done




fi # end of pile up
mv temp_cvs $the_output #for testing
mv multi_poly $the_output #for testing
mv multi_poly_names.txt $the_output #for testing

mv $the_output $The_folder
rm -f folder_names.txt

rm -f *bt2
rm -f -r temp_cvs
rm -f fofn_folders.txt

fi #this an fi for error handling dont mess with it. this is the end of the refrence
done < fofnrefs.txt #keep looping until all refrences inputed  undergone the analysis




#rm -f *csv
$Rscript $mydir/The_depth_analyser.R 2> /dev/null #run the depth analyzer which produces the final summary table
cat The_summary_final.csv Single_summary.csv  > The_summary_final2.csv
rm -f The_summary_final.csv
mv The_summary_final2.csv The_summary_final.csv
Number=`wc -l < fofn_bam.txt`


rm -f -r refrences_wide_color_scaled_graphs
mkdir refrences_wide_color_scaled_graphs #this creats folder where the graphs which will be scaled using ALL_RP_GRAPHS.R stored

echo "Thenumber: $Number"

$Rscript $mydir/All_RP_graphs.R $Number $R_packages $Normalized
mv  refrences_wide_color_scaled_graphs $The_folder


mv  *ReadMe*  $The_folder #move read me to the final folder

rm -f The_summary.txt ref_temp.txt bowtie.log  *db.2*

mv Refrences_used $The_folder


if [[ $@  ==  *"-corr"* ]]; then #if the user enter -corr check for user_provided.txt is in the same directory then run it and see if there is errors and run it

rm -f  R_all_correlation_errors.txt

if [[ !(-f user_provided.txt) ]]; then

echo "user_provided.txt wasnt provided, so the FULL correlation analysis wasnt   conducted " > R_all_correlation_errors.txt

else
rm -f -r full_correlation_graphs

mkdir full_correlation_graphs
rm -f *_corrbarplot.pdf*
$Rscript $mydir/all_corr.R $R_packages $Normalized
mv *_corrbarplot.pdf*  full_correlation_graphs
mv  full_correlation_graphs $The_folder

mv full_correlation_analysis.csv $The_folder

fi

if [ -f R_all_correlation_errors.txt ]; then


mv R_all_correlation_errors.txt $The_folder
fi



fi



mv all_depth_cvs $The_folder
mv index_conv.txt $The_folder #for testing

mv The_summary_final.csv Errors_README.log $The_folder 2> /dev/null
rm -f  *Rplots* Single_summary.csv

if [[ -f normalized_table.csv ]]; then

mv  normalized_table.csv $The_folder

fi 



rm -f  *fofn* *.out *.bam all_refs.fa
#rm -f -r images-RP  #brew stuff
rm -f -r multi_poly multi_poly_names.txt Index_conv.txt #comment when testing

#design of the cow was borrowed from the famous cowsay package

echo "________________________________"
echo "< WOW what a great pipeline !!!! >"
echo "--------------------------------"
echo "       \   ^__^"
echo "        \  (oo)\_______         "
echo "           (__)\       )\/\  "
echo "               ||----w |    "
echo "               ||     ||    "
if [[ -d $the_path ]]; then
mv $The_folder $the_path
fi



fi

#this is other commands stuff which is simple to understand  below


if [ "$1" == "pre-corr" ]; then

reads=$3

if  [[ $2 == "-u" ]] ||  [[ $2  ==  "-p" ]] ||  [[ $2  ==  "-v" ]]; then
echo "" > /dev/null


else
echo "wrong usage of pre-corr. please refer to github page on how to use it or type repeatprof -h  to review the structure"

exit 1
fi
if [ $2 = "-p" ]; then

ls ${reads}/*_R1.fastq ${reads}/*_R1.gz ${reads}/*_R1.fq  ${reads}/*_R1.fastq.gz ${reads}/*_R1.fq.gz  ${reads}/*_1.fq ${reads}/*_1.fq.gz ${reads}/*_1.gz ${reads}/*_1.fastq ${reads}/*_1.fastq.gz > fofn1.txt 2>/dev/null

ls ${reads}/*_R2.fastq ${reads}/*_R2.gz ${reads}/*_R2.fastq.gz ${reads}/*_R2.fq ${reads}/*_R2.fq.gz  ${reads}/*_2.fq.gz  ${reads}/*_2.fq ${reads}/*_2.gz ${reads}/*_2.fastq ${reads}/*_2.fastq.gz 	 > fofn2.txt 2>/dev/null


reads1_check=`cat fofn1.txt | wc -l`
reads2_check=`cat fofn2.txt | wc -l `

fi
if [ $2 = "-u" ]; then

ls ${reads}/*.fastq ${reads}/*.gz ${reads}/*.fq     > fofn1.txt 2>/dev/null

ls ${reads}/*.fastq ${reads}/*.gz ${reads}/*.fq    > fofn2.txt 2>/dev/null



reads1_check=`cat fofn1.txt | wc -l`
reads2_check=`cat fofn2.txt | wc -l `

fi






if [[ $reads1_check == 0 && $reads2_check == 0 ]];then
echo ""

echo "The path of a file of  paired  read  provided doesnt contain any paired read that has correct format."| tee -a Errors_README.log
echo "Make sure your read pairs  are in .fastq or .gz or .fq AND revise the path inputed"| tee -a Errors_README.log
echo "Analysis wont be able to continue due to the failure of finding reads"
exit 1


fi

if [ "$reads1_check" != "$reads2_check" ]; then

echo "There is a pair of read missing. Please check the folder where you have your paired reads "| tee -a Errors_README.log
exit 1
fi

$Rscript $mydir/user_supplied_maker.R $2

echo ""



fi

if [ "$1" == "clean" ]; then
rm -f -r *bam *fofn* *.out* *multi_poly_names* *_output* *_conv* *summary* *bt2* *ref_temp* *bowtie.log* *ReadMe* *_cvs* *_temp* *db.2* *Rplots* all_refs.fa Refrences_used #images-RP #brew stuff
rm -f  -r R_all_correlation_errors.txt normalized_table.csv single_cvs Single_summary.csv
echo "remians of a broken run were cleaned successfuly "
fi
if [ "$1" == "-h" ]; then
echo ""

echo "Usage:"
echo "repeatprof profile <-p for paired reads or  -u for unpaired> <the refrence sequence path > <path of the folder containing reads> [opitonal flags]"
echo ""
echo "optional flags:"
echo "-o <folder_path>		use to specifiy an directory where the final output file  be directed to. Default: current directory"
echo "-corr				type this flag to make the correlation analysis. user_provided.txt will be assumed to be in same directory"
echo "-corr	<user_provided.txt path >   type this flag to make the correlation analysis providing User_provided.txt path"

echo "-k				use this flag if you want to keep the sorted bam files of the alignments in the final output folder"

echo ""

echo "other optional flags can be used:"

echo "--very-sensitive		bowtie alignment setting. Default:--very-sensitive"
echo "--very-fast			bowtie alignment setting. Default:--very-sensitive"
echo "--local				bowtie alignment setting. Default:--very-sensitive"
echo "--fast				bowtie alignment setting. Default:--very-sensitive"
echo "--very-fast-local		bowtie alignment setting. Default:--very-sensitive"
echo "--fast-local			bowtie alignment setting. Default:--very-sensitive"
echo "--sensitive			bowtie alignment setting. Default:--very-sensitive"
echo "--very-sensitive		bowtie alignment setting. Default:--very-sensitive"
echo "--very-sensitive-local	        bowtie alignment setting. Default:--very-sensitive"
echo "--sensitive-local		bowtie alignment setting. Default:--very-sensitive"


echo ""



echo "Supported input formats:"
echo "reference:	.fa .fasta .txt "

echo "Paired reads: _R1.fastq _R1.fastq.gz _R1.fq  _R1.fq.gz  _1.fastq _1.fastq.gz _1.fq  _1.fq.gz  "
echo "              _R2.fastq _R2.fastq.gz _R2.fq  _R2.fq.gz  _2.fastq _2.fastq.gz _2.fq  _2.fq.gz  "
echo "Unpaired reads:  .fastq .fastq.gz .fq  .fq.gz  .fastq .fastq.gz .fq"

echo ""

echo "refrences need to be in fasta format. They can be multi-sequence or single sequence fasta file."

echo ""








echo "--------------------------------other usages: "
echo ""

echo "repeatprof pre-corr <-u for unpaired reads  or -p paired reads> <path of the folder containing reads> use this command to help prepare user_provided.txt for correlation graph produced by -corr flag in profile "
echo ""

echo "repeatprof pre-corr -v  use this command to review your edited user_provided.txt with your desired groups. This ensures that it is still in the correct file format. Need to be in same directory as file"
echo ""

echo "repeatprof clean		use this command to cleanup a broken/terminated run"

echo ""




echo "check our github page https://github.com/johnssproul/RepeatProfiler for more  detailed info  on how to run the tool/sample inputs/ output explanation/tutorial "


fi
